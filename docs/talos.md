# Documentation about Talos Adjustments

This document describes adjustments made to the default controlplane
configuration generated by Talos, in order to setup a single node cluster
with additional features, such as persistent storage.

**Notes**:

- When adjusting manually, after each adjustment, run
  `taloctl apply config -f <path-to-config>/controlplane.yaml`,
  this document assumes the talos cluster was already bootstrapped.
- This document is intended as a guide, it's recommneded to use patches instead
  so they can be stored in version control.
- The commands here assume, that endpoints and nodes have been configured in
  the talos config (default `~/talos/config`).
  (`contexts.<cluster>.endpoints[<single-node-cluster-ip>]`
  and `contexts.<cluster>.nodes[<single-node-cluster-ip>]`)

## Single Node Cluster

To create a single node cluster, scheduling pods on the controlplane needs
to be enabled. After running `talosctl get config <cluster> <endpoint>`, edit the
`controlplane.yaml` and set `cluster.allowSchedulingOnControlPlanes: true`.

[source](https://www.talos.dev/v1.9/talos-guides/howto/workers-on-controlplane/)

## Local storage

To enable persistence in the single node cluster with local node storage, the
`controlplane.yaml` needs to be adjusted to mount the local disk to the kubelet
container.

```yaml
machine:
  kubelet:
    extraMounts:
      - destination: /var/mnt
        type: bind
        source: /var/mnt
        options:
          - bind
          - rshared
          - rw
```

Then, the [Local Path Provisioner](https://github.com/rancher/local-path-provisioner)
needs to be installed.
See the [HelmRelease](/infrastructure/storage/local-path-provisioner.yaml) for
reference.

[source](https://www.talos.dev/v1.8/kubernetes-guides/configuration/local-storage/)

## Cilium CNI

To use a custom CNI such as Cilium, the default installation needs to be disabled
(the kube-proxy is also diabled as Cilium can be used as a replacement):

```yaml
cluster:
  network:
    cni:
      name: none
  proxy:
    disabled: true 
```

Then the Cilium CNI can be installed
[using e.g. Helm](https://www.talos.dev/v1.9/kubernetes-guides/network/deploying-cilium/#installation-using-helm)
(there is a [helper script](../helpers/install-cilium.sh) which does this).

Note: After prometheus is bootstrapped in the cluster, the script can be rerun
with `--with-prometheus` to deploy serviceMonitors and Grafana dashboards

[source](https://www.talos.dev/v1.9/kubernetes-guides/network/deploying-cilium/)

## Kube Metrics with kube-prometheus-stack

**NOTE**: These changes will open the ports on the node, so be careful.

In order to query metrics from kubernetes components, we need to change the
listening ports of the pods deployed by talos:
Add the extra argument to the proxy pod:
`cluster.proxy.extraArgs: [metrics-bind-address: 0.0.0.0:10249]`

Similar configuration changes are neede for the `controller-manager` and the
`scheduler`. But there the `extraArgs` are `[bind-address: 0.0.0.0]`.

And etcd: `extraArgs: [listen-metrics-urls: http://0.0.0.0:2381]`
Still, this also needs an additional change in the HelmRelease as etcd is not
running as pod in talos. Add the following to the `values` section:

```yaml
kubeEtcd:
  endpoints:
    - <node-local-network-ip>
```

(this might change also require `talosctl upgrade-k8s`)

[source 1](https://github.com/siderolabs/talos/discussions/7799)
[source 2](https://github.com/prometheus-operator/kube-prometheus/issues/718)
[source 3](https://github.com/siderolabs/talos/discussions/7214)

### Ingress Firewall

**NOTE**: It's advised to wait with this until the cluster is setup. It can then
be applied with `--mode=try` to see if all works before enforcing it

Since we opened the services on all interfaces, we now make sure to block
request coming from external, allowing only API and HTTP/HTTPS traffic.

**NOTE**: Talos is not able to block kubernetes created ports, such as
[NodePort services](https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport).
This is because those are already processed in the pre-routing table.
[source](https://ronaknathani.com/blog/2020/07/kubernetes-nodeport-and-iptables-rules/);
[source](https://learnk8s.io/kubernetes-services-and-load-balancing#kube-proxy-and-iptables-rules);
[source](https://stackoverflow.com/questions/62923633/use-iptables-to-block-all-kubernetes-nodeport-communication-from-outside-of-clus);
[source](https://routemyip.com/posts/k8s/networking/nodeport-iptable-under-the-hood/)

To block NodePorts a CNI which provides this functionality needs to be used, e.g. cilium.
(Note: this does not seem to work either, currently NodePorts are open, but
traffic is then blocked with NetworkPolicies inside the cluster)

See the full list of rules in the [patch](../config/controlplane-patch.yaml).

## DNS Settings

To use differend DNS servers, adjust the `machine.network.nameservers`. For example:

```yaml
machine:
  network:
    nameservers:
      - 192.168.178.1
      - 9.9.9.9
      - 8.8.8.8
```

## Automatic Patching

Instead of adding the changes mentioned above manually to the file
talosctl can be leveraged to
[apply patches](https://www.talos.dev/v1.5/talos-guides/configuration/patching/).
The [patch](../config/controlplane-patch.yaml) can be used like this:

```bash
talosctl machineconfig patch \
  --patch @config/controlplane-patch.yaml \
  ~/controlplane.yaml
```

Or directly on the node when the default was installed:

```bash
talosctl patch mc --patch @config/controlplane-patch.yaml
```
